{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "from torchsummary import summary\n",
    "import torch.utils.data as utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comp = 'FabioPC'\n",
    "if Comp == 'FabioPC':\n",
    "    df = pd.read_csv('/media/fabio/Disco locale/Fabio/Programmazione/Python/Poliambulanza/Alzheimer/Dati/ADNI/ADNI_TOT_1_10_2020.csv')\n",
    "else:\n",
    "    df = pd.read_csv('D:/ADNI/Dati/ADNI1_T1_2_11_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Acq Date</th>\n",
       "      <th>Format</th>\n",
       "      <th>Downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1270076</td>\n",
       "      <td>002_S_5178</td>\n",
       "      <td>SMC</td>\n",
       "      <td>M</td>\n",
       "      <td>75</td>\n",
       "      <td>103</td>\n",
       "      <td>MRI</td>\n",
       "      <td>HighResHippocampus</td>\n",
       "      <td>Original</td>\n",
       "      <td>11/25/2019</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1270075</td>\n",
       "      <td>002_S_5178</td>\n",
       "      <td>SMC</td>\n",
       "      <td>M</td>\n",
       "      <td>75</td>\n",
       "      <td>103</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Sagittal 3D FLAIR</td>\n",
       "      <td>Original</td>\n",
       "      <td>11/25/2019</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1270074</td>\n",
       "      <td>002_S_5178</td>\n",
       "      <td>SMC</td>\n",
       "      <td>M</td>\n",
       "      <td>75</td>\n",
       "      <td>103</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Field Mapping</td>\n",
       "      <td>Original</td>\n",
       "      <td>11/25/2019</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1270072</td>\n",
       "      <td>002_S_5178</td>\n",
       "      <td>SMC</td>\n",
       "      <td>M</td>\n",
       "      <td>75</td>\n",
       "      <td>103</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Axial 3TE T2 STAR</td>\n",
       "      <td>Original</td>\n",
       "      <td>11/25/2019</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1270071</td>\n",
       "      <td>002_S_5178</td>\n",
       "      <td>SMC</td>\n",
       "      <td>M</td>\n",
       "      <td>75</td>\n",
       "      <td>103</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Axial 3TE T2 STAR</td>\n",
       "      <td>Original</td>\n",
       "      <td>11/25/2019</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image Data ID     Subject Group Sex  Age  Visit Modality  \\\n",
       "0        1270076  002_S_5178   SMC   M   75    103      MRI   \n",
       "1        1270075  002_S_5178   SMC   M   75    103      MRI   \n",
       "2        1270074  002_S_5178   SMC   M   75    103      MRI   \n",
       "3        1270072  002_S_5178   SMC   M   75    103      MRI   \n",
       "4        1270071  002_S_5178   SMC   M   75    103      MRI   \n",
       "\n",
       "          Description      Type    Acq Date Format Downloaded  \n",
       "0  HighResHippocampus  Original  11/25/2019    DCM        NaN  \n",
       "1   Sagittal 3D FLAIR  Original  11/25/2019    DCM        NaN  \n",
       "2       Field Mapping  Original  11/25/2019    DCM        NaN  \n",
       "3   Axial 3TE T2 STAR  Original  11/25/2019    DCM        NaN  \n",
       "4   Axial 3TE T2 STAR  Original  11/25/2019    DCM        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Translation Transform*\n"
     ]
    }
   ],
   "source": [
    "interpolator = sitk.sitkLinear\n",
    "default_value = 0\n",
    "print('*Translation Transform*')\n",
    "transform = sitk.TranslationTransform(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Comp == 'FabioPC':\n",
    "    IMG_Folder = '/media/fabio/Disco locale/Fabio/Programmazione/Python/Poliambulanza/Alzheimer/Dati/ADNI/ADNI_Prova/'\n",
    "else:\n",
    "    IMG_Folder = 'D:/ADNI/Dati/ADNI_T1/ADNI1_T1/ADNI_Registrate/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dati_img = os.listdir(IMG_Folder)\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/fabio/Disco locale/Fabio/Programmazione/Python/Poliambulanza/Alzheimer/ADNI/LeNet5_CNN'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (10).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (11).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (12).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (13).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (14).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (15).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (2).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (3).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (4).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (5).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (6).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (7).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (8).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (9).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (1).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (10).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (11).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (12).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (2).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (3).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (4).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (5).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (6).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (7).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (8).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (9).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119.nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (1).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (10).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (11).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (12).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (13).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (14).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (15).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (2).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (3).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (1).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (10).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (11).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (12).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (13).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (14).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (15).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (2).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114.nii',\n",
       " 'ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (3).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106.nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (1).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118.nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (4).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (4).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (5).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (6).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (7).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (8).nii',\n",
       " 'ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (9).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (5).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (6).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (7).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (8).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (9).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116.nii',\n",
       " 'H5Corrette',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (10).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (11).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (12).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (13).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (14).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (15).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (2).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (3).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (4).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (5).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (6).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (7).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (8).nii',\n",
       " 'ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (9).nii']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dati_img[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Comp == 'FabioPC':\n",
    "    dati_img[0].split('_')[1:4]\n",
    "else:\n",
    "    dati_img[0].split('_')[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Comp == 'FabioPC':\n",
    "    ID = '_'.join(dati_img[0].split('_')[1:4])\n",
    "else:\n",
    "    ID = '_'.join(dati_img[0].split('_')[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'002_S_0295'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MRI'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Subject'] == ID]['Modality'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_image = sitk.ReadImage(IMG_Folder + dati_img[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already Created\n",
      "ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (10).nii\n",
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (11).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 2/77 [00:00<00:19,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (12).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 3/77 [00:00<00:22,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (13).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 4/77 [00:01<00:25,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (14).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 5/77 [00:01<00:27,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (15).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 6/77 [00:02<00:27,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (2).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 7/77 [00:02<00:28,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (3).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 8/77 [00:03<00:28,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (4).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 9/77 [00:03<00:29,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (5).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 10/77 [00:04<00:28,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (6).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 11/77 [00:04<00:28,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (7).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 12/77 [00:04<00:28,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (8).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 13/77 [00:05<00:28,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114 (9).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 14/77 [00:05<00:27,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (1).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 15/77 [00:06<00:27,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (10).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 16/77 [00:06<00:26,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (11).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 17/77 [00:07<00:27,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (12).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 18/77 [00:07<00:27,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (2).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 19/77 [00:08<00:28,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (3).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 20/77 [00:08<00:27,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (4).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 21/77 [00:09<00:27,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (5).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 22/77 [00:09<00:28,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (6).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 23/77 [00:10<00:27,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (7).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 24/77 [00:10<00:27,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (8).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 25/77 [00:11<00:27,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119 (9).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 26/77 [00:11<00:26,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp_Br_20070319115721424_S13893_I45119.nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 27/77 [00:12<00:29,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (1).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 28/77 [00:13<00:28,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (10).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 29/77 [00:13<00:27,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (11).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 30/77 [00:14<00:26,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (12).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 31/77 [00:14<00:25,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (13).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 32/77 [00:15<00:23,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (14).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 33/77 [00:15<00:22,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (15).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 34/77 [00:16<00:22,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (2).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 35/77 [00:16<00:21,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (3).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 36/77 [00:17<00:21,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (1).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 37/77 [00:17<00:20,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(256, 256, 166)\n",
      "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (10).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 38/77 [00:18<00:21,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(256, 256, 166)\n",
      "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (11).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 39/77 [00:19<00:21,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(256, 256, 166)\n",
      "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (12).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 40/77 [00:19<00:21,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(256, 256, 166)\n",
      "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (13).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 41/77 [00:20<00:20,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(256, 256, 166)\n",
      "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (14).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 42/77 [00:20<00:20,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(256, 256, 166)\n",
      "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (15).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 43/77 [00:21<00:19,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(256, 256, 166)\n",
      "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (2).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 44/77 [00:22<00:19,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(256, 256, 166)\n",
      "ADNI_002_S_0295_MR_MPR-R__GradWarp_Br_20070319114720743_S13407_I45114.nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 45/77 [00:22<00:19,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (3).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 46/77 [00:23<00:18,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(256, 256, 166)\n",
      "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106.nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 47/77 [00:23<00:17,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(256, 256, 166)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (1).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 48/77 [00:24<00:17,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118.nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 49/77 [00:25<00:17,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (4).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 50/77 [00:25<00:16,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (4).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 51/77 [00:26<00:16,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(256, 256, 166)\n",
      "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (5).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 52/77 [00:27<00:17,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(256, 256, 166)\n",
      "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (6).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 53/77 [00:27<00:16,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(256, 256, 166)\n",
      "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (7).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 54/77 [00:28<00:16,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(256, 256, 166)\n",
      "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (8).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 55/77 [00:29<00:15,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(256, 256, 166)\n",
      "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__Mask_Br_20070319113323272_S13408_I45106 (9).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 56/77 [00:30<00:14,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(256, 256, 166)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (5).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 57/77 [00:30<00:13,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (6).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 58/77 [00:31<00:13,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (7).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 59/77 [00:32<00:12,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (8).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 60/77 [00:32<00:11,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116 (9).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 61/77 [00:33<00:11,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction__N3_Br_20070319115122015_S13893_I45116.nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 62/77 [00:34<00:10,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (10).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 64/77 [00:35<00:08,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (11).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 65/77 [00:36<00:08,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (12).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 66/77 [00:37<00:08,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (13).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 67/77 [00:37<00:08,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (14).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 68/77 [00:38<00:07,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (15).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 69/77 [00:39<00:06,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (2).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 70/77 [00:40<00:05,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (3).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 71/77 [00:41<00:05,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (4).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▎| 72/77 [00:42<00:04,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (5).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 73/77 [00:43<00:03,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (6).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 74/77 [00:44<00:02,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (7).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 75/77 [00:45<00:01,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (8).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▊| 76/77 [00:46<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n",
      "ADNI_002_S_0413_MR_MPR__GradWarp__B1_Correction_Br_20070319115531324_S13893_I45118 (9).nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 77/77 [00:47<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CN\n",
      "(166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "img_tot = []\n",
    "y = []\n",
    "try:\n",
    "    os.makedirs('ADNI1_PROC')\n",
    "except:\n",
    "    print(\"Already Created\")\n",
    "for data_img in tqdm(dati_img[1:]):\n",
    "    if 'nii' in str(data_img):\n",
    "        print(str(data_img))\n",
    "        sitk_t1 = sitk.ReadImage(IMG_Folder + data_img)\n",
    "        #print(sitk_t1.GetDirection())\n",
    "        #t2 = sitk.Resample(sitk_t1, reference_image, transform,interpolator, default_value)\n",
    "        t1 = sitk.GetArrayFromImage(sitk_t1)\n",
    "        img_tot.append(t1)\n",
    "        print()\n",
    "        if Comp == 'FabioPC':\n",
    "            Subject = df.loc[df['Subject'] == '_'.join(data_img.split('_')[1:4])]['Group'].values[0]\n",
    "        else:\n",
    "            Subject = df.loc[df['Subject'] == '_'.join(data_img.split('_')[2:5])]['Group'].values[0]\n",
    "        print(Subject)\n",
    "        y.append(Subject)\n",
    "        #sitk.WriteImage(t2,'ADNI1_PROC/'+ str(data_img))\n",
    "\n",
    "        print(t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chunks = 77\n",
    "N = len(img_tot)\n",
    "chunks = np.linspace(0, N, num_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [int(chunk) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Già creata\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if Comp == 'FabioPC':\n",
    "        os.makedirs('/media/fabio/Disco locale/Fabio/Programmazione/Python/Poliambulanza/Alzheimer/Dati/ADNI/ADNI_Prova/H5Corrette')\n",
    "    else:\n",
    "        os.makedirs('D:/ADNI/Dati/ADNI_T1/ADNI1_T1/ADNI_Registrate/H5Corrette')\n",
    "except:\n",
    "    print('Già creata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "2\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "4\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "8\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "(1, 166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "11\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "13\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "14"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "16\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "17\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "19\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "21\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "22\n",
      "[[1.]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1, 166, 256, 256)\n",
      "23\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "27\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "29\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "31\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "33\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n",
      "35\n",
      "[[1.]]\n",
      "(1, 166, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "[[1.]]\n",
      "(1, 256, 256, 166)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can't broadcast (1, 256, 256, 166) -> (166, 256, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-c1bd28fb7d81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mimg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m166\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mlabel_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mimg_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_img_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mlabel_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mmshape_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNLIMITED\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/h5py/_hl/selections.py\u001b[0m in \u001b[0;36mbroadcast\u001b[0;34m(self, target_shape)\u001b[0m\n\u001b[1;32m    297\u001b[0m                     \u001b[0mtshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't broadcast %s -> %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't broadcast (1, 256, 256, 166) -> (166, 256, 256)"
     ]
    }
   ],
   "source": [
    "if Comp == 'FabioPC':\n",
    "    hf = h5py.File('/media/fabio/Disco locale/Fabio/Programmazione/Python/Poliambulanza/Alzheimer/Dati/ADNI/ADNI_Prova/H5Corrette/data_img.h5', 'w')\n",
    "else:\n",
    "    hf = h5py.File('D:/ADNI/Dati/ADNI_T1/ADNI1_T1/ADNI_Registrate/H5Corrette/data_img.h5', 'w')\n",
    "img_data = hf.create_dataset('data', (1, 166, 256, 256), maxshape=(None, None, None, None))\n",
    "label_data = hf.create_dataset('label', (1,1), maxshape=(None, None))\n",
    "for i in range(len(chunks) -1):\n",
    "    grp = hf.create_group(\"group_{}\".format(i))\n",
    "    \n",
    "    print(i)\n",
    "    sub_img_tot = img_tot[chunks[i]:chunks[i+1]]\n",
    "    label = y[chunks[i]:chunks[i+1]]\n",
    "    \n",
    "    label = label_encoder.fit_transform(label)\n",
    "    enc = OneHotEncoder()\n",
    "\n",
    "    # 2. FIT\n",
    "    enc.fit(label.reshape(-1, 1))\n",
    "\n",
    "    # 3. Transform\n",
    "    label = enc.transform(label.reshape(-1, 1)).toarray()\n",
    "    print(label)\n",
    "    sub_img_array = np.asarray(sub_img_tot)\n",
    "    print(sub_img_array.shape)\n",
    "    img_data.resize((i+1, 166, 256, 256))\n",
    "    label_data.resize((i+1,1))\n",
    "    img_data[i,:,:,:] = sub_img_array\n",
    "    label_data[i] = label\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date = np.asarray(img_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = label_encoder.fit_transform(y)\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "# 2. FIT\n",
    "enc.fit(y.reshape(-1, 1))\n",
    "\n",
    "# 3. Transform\n",
    "y = onehotlabels = enc.transform(y.reshape(-1, 1)).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(date, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0][:, 100, :], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"Arguments:\n",
    "        img (tensor)\n",
    "        label (tensor)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img, label):\n",
    "    \n",
    "        self.img = img\n",
    "        self.label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.img[index]\n",
    "        \n",
    "        label = self.label[index]\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = torch.from_numpy(Y_train)\n",
    "t1 = torch.from_numpy(X_train)\n",
    "dataset = CustomDataset(t1, t2)\n",
    "dataloader = utils.DataLoader(dataset, batch_size=1, num_workers=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 10, kernel_size=(5, 5, 5))\n",
    "        self.conv2 = nn.Conv3d(10, 20, kernel_size=(5, 5, 5))\n",
    "        self.conv2_drop = nn.Dropout3d()\n",
    "        self.fc1 = nn.Linear(38 * 61 * 61 * 20, 50)\n",
    "        self.fc2 = nn.Linear(50,3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool3d(self.conv1(x), (2, 2, 2)))\n",
    "        x = F.relu(F.max_pool3d(self.conv2_drop(self.conv2(x)), (2, 2, 2)))\n",
    "        x = x.view(-1, 38 * 61 * 61 * 20)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 540.00 MiB (GPU 0; 1.95 GiB total capacity; 421.48 MiB already allocated; 330.88 MiB free; 256.52 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-db44a86a0a56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# PyTorch v0.4.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m52\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m92\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 540.00 MiB (GPU 0; 1.95 GiB total capacity; 421.48 MiB already allocated; 330.88 MiB free; 256.52 MiB cached)"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "model = Net().to(device)\n",
    "summary(model, (1, 52, 92, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-5, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#x = torch.randn(2, 1, 192, 192, 160, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(10, 1, 52, 92, 80)).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")) # (N,C,D,H,W)\n",
    "# print(x)\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.randn(10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    loss_list, batch_list = [], []\n",
    "\n",
    "    #for num, (img, label) in enumerate(dataloader):\n",
    "        #inputs = img.unsqueeze(0)\n",
    "    print()\n",
    "    output = model(x.float().to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n",
    "    loss = criterion(output, label.float().to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n",
    "    optimizer.zero_grad()\n",
    "    loss_list.append(loss.detach().cpu().item())\n",
    "    batch_list.append(i+1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Train - Epoch %d, Batch: %d, Loss: %f' % (i, num, loss.detach().cpu().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' SCRIPT DA USARE PER 3D SLICER \n",
    "\n",
    "##################################################\n",
    "##################################################\n",
    "##################################################\n",
    "\n",
    ">>> scene = slicer.mrmlScene\n",
    ">>> slicer.util.selectModule('BRAINSFit')\n",
    ">>> brainsFit = slicer.modules.brainsfit\n",
    "\n",
    ">>> [ success,movingVolumeNode ] = slicer.util.loadVolume('/media/fabio/Disco locale/Scaricati/ADNI1_ex/ADNI/002_S_0559/MPR-R__GradWarp__B1_Correction__N3/2006-05-23_15_09_38.0/S14876/ADNI_002_S_0559_MR_MPR-R__GradWarp__B1_Correction__N3_Br_20070216235035331_S14876_I40678.nii',returnNode=True)\n",
    ">>> movingVolumeNode\n",
    "(MRMLCorePython.vtkMRMLScalarVolumeNode)0x7f5738020d50\n",
    ">>> success\n",
    "True\n",
    "\n",
    ">>> [ success, fixedVolumeNode ] = slicer.util.loadVolume('/media/fabio/Disco locale/Scaricati/ADNI1_ex/ADNI/011_S_0008/MPR-R__GradWarp__B1_Correction__N3/2005-09-13_13_33_53.0/S9195/ADNI_011_S_0008_MR_MPR-R__GradWarp__B1_Correction__N3_Br_20061208113724677_S9195_I32254.nii', returnNode = True)\n",
    ">>> success\n",
    "True\n",
    ">>> parameterRigid = {}\n",
    ">>> linearTransform = slicer.vtkMRMLLinearTransformNode()\n",
    ">>> parameterRigid[\"linearTransform\"] = linearTransform.GetID()\n",
    ">>> parameterRigid[\"useRigid\"] = True\n",
    ">>> slicer.cli.run(brainsFit, None, parameterRigid)\n",
    "parameter  linearTransform  has unsupported type  NoneType\n",
    "(MRMLCLIPython.vtkMRMLCommandLineModuleNode)0x7f5738020e20\n",
    ">>> parameterRigid[\"fixedVolume\"] = fixedVolumeNode\n",
    ">>> parameterRigid[\"movingVolume\"] = movingVolumeNode\n",
    ">>> slicer.cli.run(brainsFit, None, parameterRigid)\n",
    "parameter  linearTransform  has unsupported type  NoneType\n",
    "(MRMLCLIPython.vtkMRMLCommandLineModuleNode)0x7f5738030328\n",
    ">>> slicer.mrmlScene.AddNode( linearTransform )\n",
    "(MRMLCorePython.vtkMRMLLinearTransformNode)0x7f5738020e88\n",
    ">>> slicer.cli.run(brainsFit, None, parameterRigid)\n",
    "parameter  linearTransform  has unsupported type  NoneType\n",
    "(MRMLCLIPython.vtkMRMLCommandLineModuleNode)0x7f5738020db8\n",
    ">>> parameterRigid[\"linearTransform\"] = linearTransform.GetID()\n",
    ">>> slicer.cli.run(brainsFit, None, parameterRigid)\n",
    "(MRMLCLIPython.vtkMRMLCommandLineModuleNode)0x7f5738030328\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> a\n",
    "(MRMLCLIPython.vtkMRMLCommandLineModuleNode)0x7f5738020e20\n",
    ">>> a.GetStatusString()\n",
    "'Completed'\n",
    ">>> linearTransform = slicer.vtkMRMLLinearTransformNode()\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> a.GetStatusString()\n",
    "'Completed'\n",
    ">>> parameterRigid[\"useRigid\"] = True\n",
    ">>> parameterRigid[\"samplingPercentage\"] = 0.002\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> parameterRigid[\"samplingPercentage\"] = 0.02\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> a.GetStatus()\n",
    "2\n",
    "\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> a.GetStatus()\n",
    "2\n",
    ">>> a.GetStatus()\n",
    "32\n",
    ">>> parameterRigid[\"samplingPercentage\"] = 0.002\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> parameterRigid[\"samplingPercentage\"] = 0.02\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> parameterRigid[\"samplingPercentage\"] = 0.002\n",
    ">>> \n",
    ">>> parameterRigid[\"initializeTransformMode\"] = \"useCenterOfHead\"\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> a.GetStatus()\n",
    "96\n",
    ">>> a.GetStatus()\n",
    "96\n",
    ">>> a.GetStatus()\n",
    "96\n",
    ">>> a.GetStatus()\n",
    "96\n",
    ">>> a.GetStatusString()\n",
    "'Completed with errors'\n",
    ">>> a.GetErrorText()\n",
    "\"General Registration (BRAINS) standard error:\\n\\nPARSE ERROR: Argument: (--initializeTransformMode)\\n             Value 'useCenterOfHead' does not meet constraint: Off|useMomentsAlign|useCenterOfHeadAlign|useGeometryAlign|useCenterOfROIAlign\\n\\nBrief USAGE: \\n\\nFor complete USAGE and HELP type: \\n   /media/fabio/Disco locale/Scaricati/Slicer-4.10.2-linux-amd64/bin/../lib/Slicer-4.10/cli-modules/BRAINSFit --help\\n\\n\"\n",
    ">>> parameterRigid[\"initializeTransformMode\"] = \"useCenterOfHeadAlign\"\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> a.GetStatusString()\n",
    "'Running'\n",
    ">>> a.GetStatus()\n",
    "2\n",
    ">>> a.GetStatusString()\n",
    "'Running'\n",
    ">>> a.GetStatus()\n",
    "2\n",
    ">>> a.GetStatus()\n",
    "2\n",
    ">>> a.GetStatusString()\n",
    "'Running'\n",
    ">>> a.GetStatusString()\n",
    "'Running'\n",
    ">>> a.GetErrorText()\n",
    "''\n",
    ">>> a.GetStatusString()\n",
    "'Completed'\n",
    ">>> a.GetStatusString()\n",
    "'Completed'\n",
    ">>> \n",
    ">>> \n",
    ">>> parameterRigid[\"samplingPercentage\"] = 0.02\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> a.GetStatusString()\n",
    "'Running'\n",
    ">>> a.GetStatusString()\n",
    "'Running'\n",
    ">>> a.GetStatusString()\n",
    "'Completed'\n",
    ">>> \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
