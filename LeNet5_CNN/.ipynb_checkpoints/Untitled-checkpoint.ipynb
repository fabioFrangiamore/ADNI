{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "from torchsummary import summary\n",
    "import torch.utils.data as utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/ADNI/Dati/ADNI1_T1_2_11_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolator = sitk.sitkLinear\n",
    "default_value = 0\n",
    "print('*Translation Transform*')\n",
    "transform = sitk.TranslationTransform(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_Folder = 'D:/ADNI/Dati/ADNI_T1/ADNI1_T1/ADNI_Registrate/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dati_img = os.listdir(IMG_Folder)\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dati_img[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dati_img[0].split('_')[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '_'.join(dati_img[0].split('_')[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Subject'] == ID]['Modality'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_image = sitk.ReadImage(IMG_Folder + dati_img[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tot = []\n",
    "y = []\n",
    "try:\n",
    "    os.makedirs('ADNI1_PROC')\n",
    "except:\n",
    "    print(\"Already Created\")\n",
    "for data_img in tqdm(dati_img[1:]):\n",
    "    if 'nii' in str(data_img):\n",
    "        print(str(data_img))\n",
    "        sitk_t1 = sitk.ReadImage(IMG_Folder + data_img)\n",
    "        #print(sitk_t1.GetDirection())\n",
    "        #t2 = sitk.Resample(sitk_t1, reference_image, transform,interpolator, default_value)\n",
    "        t1 = sitk.GetArrayFromImage(sitk_t1)\n",
    "        img_tot.append(t1)\n",
    "        print()\n",
    "        Subject = df.loc[df['Subject'] == '_'.join(data_img.split('_')[2:5])]['Group'].values[0]\n",
    "        print(Subject)\n",
    "        y.append(Subject)\n",
    "        #sitk.WriteImage(t2,'ADNI1_PROC/'+ str(data_img))\n",
    "\n",
    "        print(t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chunks = 30 \n",
    "N = len(img_tot)\n",
    "chunks = np.linspace(0, N, num_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [int(chunk) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs('D:/ADNI/Dati/ADNI_T1/ADNI1_T1/ADNI_Registrate/H5Corrette')\n",
    "except:\n",
    "    print('Gi√† creata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "hf = h5py.File('D:/ADNI/Dati/ADNI_T1/ADNI1_T1/ADNI_Registrate/H5Corrette/data_img.h5', 'w')\n",
    "for i in range(len(chunks) -1):\n",
    "    grp = hf.create_group(\"group_{}\".format(i))\n",
    "    \n",
    "    print(i)\n",
    "    sub_img_tot = img_tot[chunks[i]:chunks[i+1]]\n",
    "    label = y[chunks[i]:chunks[i+1]]\n",
    "    \n",
    "    label = label_encoder.fit_transform(label)\n",
    "    enc = OneHotEncoder()\n",
    "\n",
    "    # 2. FIT\n",
    "    enc.fit(label.reshape(-1, 1))\n",
    "\n",
    "    # 3. Transform\n",
    "    label = onehotlabels = enc.transform(label.reshape(-1, 1)).toarray()\n",
    "    print(label)\n",
    "    sub_img_array = np.asarray(sub_img_tot)\n",
    "    print(sub_img_array.shape)\n",
    "    grp.create_dataset('data', data=sub_img_array)\n",
    "    grp.create_dataset('label', data=label)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date = np.asarray(img_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = label_encoder.fit_transform(y)\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "# 2. FIT\n",
    "enc.fit(y.reshape(-1, 1))\n",
    "\n",
    "# 3. Transform\n",
    "y = onehotlabels = enc.transform(y.reshape(-1, 1)).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(date, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0][:, 100, :], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"Arguments:\n",
    "        img (tensor)\n",
    "        label (tensor)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img, label):\n",
    "    \n",
    "        self.img = img\n",
    "        self.label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.img[index]\n",
    "        \n",
    "        label = self.label[index]\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = torch.from_numpy(Y_train)\n",
    "t1 = torch.from_numpy(X_train)\n",
    "dataset = CustomDataset(t1, t2)\n",
    "dataloader = utils.DataLoader(dataset, batch_size=1, num_workers=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 10, kernel_size=(5, 5, 5))\n",
    "        self.conv2 = nn.Conv3d(10, 20, kernel_size=(5, 5, 5))\n",
    "        self.conv2_drop = nn.Dropout3d()\n",
    "        self.fc1 = nn.Linear(38 * 61 * 61 * 20, 50)\n",
    "        self.fc2 = nn.Linear(50,3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool3d(self.conv1(x), (2, 2, 2)))\n",
    "        x = F.relu(F.max_pool3d(self.conv2_drop(self.conv2(x)), (2, 2, 2)))\n",
    "        x = x.view(-1, 38 * 61 * 61 * 20)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 540.00 MiB (GPU 0; 1.95 GiB total capacity; 421.48 MiB already allocated; 330.88 MiB free; 256.52 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-db44a86a0a56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# PyTorch v0.4.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m52\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m92\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 540.00 MiB (GPU 0; 1.95 GiB total capacity; 421.48 MiB already allocated; 330.88 MiB free; 256.52 MiB cached)"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "model = Net().to(device)\n",
    "summary(model, (1, 52, 92, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-5, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#x = torch.randn(2, 1, 192, 192, 160, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(10, 1, 52, 92, 80)).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")) # (N,C,D,H,W)\n",
    "# print(x)\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.randn(10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    loss_list, batch_list = [], []\n",
    "\n",
    "    #for num, (img, label) in enumerate(dataloader):\n",
    "        #inputs = img.unsqueeze(0)\n",
    "    print()\n",
    "    output = model(x.float().to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n",
    "    loss = criterion(output, label.float().to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n",
    "    optimizer.zero_grad()\n",
    "    loss_list.append(loss.detach().cpu().item())\n",
    "    batch_list.append(i+1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Train - Epoch %d, Batch: %d, Loss: %f' % (i, num, loss.detach().cpu().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' SCRIPT DA USARE PER 3D SLICER \n",
    "\n",
    "##################################################\n",
    "##################################################\n",
    "##################################################\n",
    "\n",
    ">>> scene = slicer.mrmlScene\n",
    ">>> slicer.util.selectModule('BRAINSFit')\n",
    ">>> brainsFit = slicer.modules.brainsfit\n",
    "\n",
    ">>> [ success,movingVolumeNode ] = slicer.util.loadVolume('/media/fabio/Disco locale/Scaricati/ADNI1_ex/ADNI/002_S_0559/MPR-R__GradWarp__B1_Correction__N3/2006-05-23_15_09_38.0/S14876/ADNI_002_S_0559_MR_MPR-R__GradWarp__B1_Correction__N3_Br_20070216235035331_S14876_I40678.nii',returnNode=True)\n",
    ">>> movingVolumeNode\n",
    "(MRMLCorePython.vtkMRMLScalarVolumeNode)0x7f5738020d50\n",
    ">>> success\n",
    "True\n",
    "\n",
    ">>> [ success, fixedVolumeNode ] = slicer.util.loadVolume('/media/fabio/Disco locale/Scaricati/ADNI1_ex/ADNI/011_S_0008/MPR-R__GradWarp__B1_Correction__N3/2005-09-13_13_33_53.0/S9195/ADNI_011_S_0008_MR_MPR-R__GradWarp__B1_Correction__N3_Br_20061208113724677_S9195_I32254.nii', returnNode = True)\n",
    ">>> success\n",
    "True\n",
    ">>> parameterRigid = {}\n",
    ">>> linearTransform = slicer.vtkMRMLLinearTransformNode()\n",
    ">>> parameterRigid[\"linearTransform\"] = linearTransform.GetID()\n",
    ">>> parameterRigid[\"useRigid\"] = True\n",
    ">>> slicer.cli.run(brainsFit, None, parameterRigid)\n",
    "parameter  linearTransform  has unsupported type  NoneType\n",
    "(MRMLCLIPython.vtkMRMLCommandLineModuleNode)0x7f5738020e20\n",
    ">>> parameterRigid[\"fixedVolume\"] = fixedVolumeNode\n",
    ">>> parameterRigid[\"movingVolume\"] = movingVolumeNode\n",
    ">>> slicer.cli.run(brainsFit, None, parameterRigid)\n",
    "parameter  linearTransform  has unsupported type  NoneType\n",
    "(MRMLCLIPython.vtkMRMLCommandLineModuleNode)0x7f5738030328\n",
    ">>> slicer.mrmlScene.AddNode( linearTransform )\n",
    "(MRMLCorePython.vtkMRMLLinearTransformNode)0x7f5738020e88\n",
    ">>> slicer.cli.run(brainsFit, None, parameterRigid)\n",
    "parameter  linearTransform  has unsupported type  NoneType\n",
    "(MRMLCLIPython.vtkMRMLCommandLineModuleNode)0x7f5738020db8\n",
    ">>> parameterRigid[\"linearTransform\"] = linearTransform.GetID()\n",
    ">>> slicer.cli.run(brainsFit, None, parameterRigid)\n",
    "(MRMLCLIPython.vtkMRMLCommandLineModuleNode)0x7f5738030328\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> a\n",
    "(MRMLCLIPython.vtkMRMLCommandLineModuleNode)0x7f5738020e20\n",
    ">>> a.GetStatusString()\n",
    "'Completed'\n",
    ">>> linearTransform = slicer.vtkMRMLLinearTransformNode()\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> a.GetStatusString()\n",
    "'Completed'\n",
    ">>> parameterRigid[\"useRigid\"] = True\n",
    ">>> parameterRigid[\"samplingPercentage\"] = 0.002\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> parameterRigid[\"samplingPercentage\"] = 0.02\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> a.GetStatus()\n",
    "2\n",
    "\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> a.GetStatus()\n",
    "2\n",
    ">>> a.GetStatus()\n",
    "32\n",
    ">>> parameterRigid[\"samplingPercentage\"] = 0.002\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> parameterRigid[\"samplingPercentage\"] = 0.02\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> parameterRigid[\"samplingPercentage\"] = 0.002\n",
    ">>> \n",
    ">>> parameterRigid[\"initializeTransformMode\"] = \"useCenterOfHead\"\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> a.GetStatus()\n",
    "96\n",
    ">>> a.GetStatus()\n",
    "96\n",
    ">>> a.GetStatus()\n",
    "96\n",
    ">>> a.GetStatus()\n",
    "96\n",
    ">>> a.GetStatusString()\n",
    "'Completed with errors'\n",
    ">>> a.GetErrorText()\n",
    "\"General Registration (BRAINS) standard error:\\n\\nPARSE ERROR: Argument: (--initializeTransformMode)\\n             Value 'useCenterOfHead' does not meet constraint: Off|useMomentsAlign|useCenterOfHeadAlign|useGeometryAlign|useCenterOfROIAlign\\n\\nBrief USAGE: \\n\\nFor complete USAGE and HELP type: \\n   /media/fabio/Disco locale/Scaricati/Slicer-4.10.2-linux-amd64/bin/../lib/Slicer-4.10/cli-modules/BRAINSFit --help\\n\\n\"\n",
    ">>> parameterRigid[\"initializeTransformMode\"] = \"useCenterOfHeadAlign\"\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> a.GetStatusString()\n",
    "'Running'\n",
    ">>> a.GetStatus()\n",
    "2\n",
    ">>> a.GetStatusString()\n",
    "'Running'\n",
    ">>> a.GetStatus()\n",
    "2\n",
    ">>> a.GetStatus()\n",
    "2\n",
    ">>> a.GetStatusString()\n",
    "'Running'\n",
    ">>> a.GetStatusString()\n",
    "'Running'\n",
    ">>> a.GetErrorText()\n",
    "''\n",
    ">>> a.GetStatusString()\n",
    "'Completed'\n",
    ">>> a.GetStatusString()\n",
    "'Completed'\n",
    ">>> \n",
    ">>> \n",
    ">>> parameterRigid[\"samplingPercentage\"] = 0.02\n",
    ">>> a = slicer.cli.run(brainsFit, None, parameterRigid)\n",
    ">>> a.GetStatusString()\n",
    "'Running'\n",
    ">>> a.GetStatusString()\n",
    "'Running'\n",
    ">>> a.GetStatusString()\n",
    "'Completed'\n",
    ">>> \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
